{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob\n",
    "from os import path\n",
    "\n",
    "content_names = list(os.path.splitext(\n",
    "        each)[0] for each in os.listdir(\"./input/contents\"))\n",
    "content_paths = glob.glob('./input/contents/*')\n",
    "\n",
    "test = [path.splitext(path.basename(x))[0] for x in glob.glob('./input/contents/*')]\n",
    "print(test)\n",
    "\n",
    "# print(content_names, content_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "from os import listdir, mkdir, getcwd\n",
    "import glob\n",
    "import os\n",
    "\n",
    "def import_image(file_name, height, width):\n",
    "    # import image, cast as np array\n",
    "\n",
    "    image = Image.open(file_name)  # 1.0 retrieve all input image references\n",
    "    image = image.resize((height, width), Image.ANTIALIAS)  # downsample\n",
    "    image = np.asarray(image, dtype='float32')  # cast to np array\n",
    "    image = np.expand_dims(image, axis=0)  # add placeholder dimension\n",
    "\n",
    "    image[:, :, :, 0] -= 103.939  # subtract mean RGB values from ImageNet\n",
    "    image[:, :, :, 1] -= 116.779\n",
    "    image[:, :, :, 2] -= 123.68\n",
    "    image = image[:, :, :, ::-1]  # flip RGB pixel ordering\n",
    "\n",
    "    return image\n",
    "\n",
    "\n",
    "def export_image(img_array, save_dir, height, width):\n",
    "    # export np array as jpeg image\n",
    "\n",
    "    img_array = img_array.reshape((height, width, 3))  # reshape\n",
    "    img_array = img_array[:, :, ::-1]  # flip RGB pixel ordering\n",
    "    img_array[:, :, 0] += 103.939  # add mean RGB values from ImageNet\n",
    "    img_array[:, :, 1] += 116.779\n",
    "    img_array[:, :, 2] += 123.68\n",
    "    img_array = np.clip(img_array, 0, 255).astype('uint8')  # trim pixels\n",
    "\n",
    "    Image.fromarray(img_array).save(save_dir + '.jpeg', \"jpeg\")  # save\n",
    "\n",
    "\n",
    "def retrieve_inputs():\n",
    "    # retrieve all style and content image file names/dir paths\n",
    "\n",
    "    content_names = [os.path.splitext(os.path.basename(x))[0]\n",
    "                     for x in glob.glob('./input/contents/*')]\n",
    "    content_paths = glob.glob('./input/contents/*')\n",
    "    style_names = [os.path.splitext(os.path.basename(x))[0]\n",
    "                   for x in glob.glob('./input/styles/*')]\n",
    "    style_paths = glob.glob('./input/styles/*')\n",
    "\n",
    "    return content_names, content_paths, style_names, style_paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras import backend as K\n",
    "\n",
    "def eval_loss_and_grads(x, loss, grads, composition_np, height, width):\n",
    "    '''\n",
    "    Define gradients of the total loss relative to the composition image, in\n",
    "    order to minimize the loss.\n",
    "    '''\n",
    "\n",
    "    x = x.reshape((1, height, width, 3))\n",
    "    outputs = [loss]\n",
    "    outputs += grads\n",
    "    f_outputs = K.function([composition_np], outputs)\n",
    "\n",
    "    outs = f_outputs([x])\n",
    "    prog_loss = outs[0]\n",
    "    grad_values = outs[1].flatten().astype('float64')\n",
    "\n",
    "    return prog_loss, grad_values\n",
    "\n",
    "\n",
    "class Evaluator(object):\n",
    "    '''\n",
    "    Computes the loss and gradient present within the composition image. Phrased\n",
    "    as a class to conveniently package retrieval methods for interfacing with \n",
    "    scypy.optimize library.\n",
    "    '''\n",
    "\n",
    "    def __init__(self, il, ig, comb_np, height, width):\n",
    "        self.prog_loss = None  # bundle variables as object fields.. eek\n",
    "        self.prog_grads = None\n",
    "        self.initial_loss = il\n",
    "        self.initial_grad = ig\n",
    "        self.comb_np = comb_np\n",
    "        self.height = height\n",
    "        self.width = width\n",
    "\n",
    "    def loss(self, x):\n",
    "        '''\n",
    "        Retrieve the loss value for the composition image.\n",
    "        '''\n",
    "\n",
    "        assert self.prog_loss is None\n",
    "        self.prog_loss, self.grad_values = eval_loss_and_grads(x, self.initial_loss,\n",
    "                                                               self.initial_grad,\n",
    "                                                               self.comb_np,\n",
    "                                                               self.height,\n",
    "                                                               self.width)\n",
    "\n",
    "        return self.prog_loss\n",
    "\n",
    "    def grads(self, x):\n",
    "        '''\n",
    "        Retrieve the gradients associated with a particular composition\n",
    "        image.\n",
    "        '''\n",
    "\n",
    "        assert self.prog_loss is not None\n",
    "        grad_values = np.copy(self.grad_values)\n",
    "        self.prog_loss = None\n",
    "        self.grad_values = None\n",
    "\n",
    "        return grad_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import scipy\n",
    "\n",
    "from keras.applications.vgg16 import VGG16  # \"OxfordNet\", pretrained network\n",
    "from keras import backend as K\n",
    "\n",
    "from evaluator import Evaluator\n",
    "from util import export_image\n",
    "\n",
    "\n",
    "def content_loss(content_np, composition_np):\n",
    "    '''\n",
    "    Calculate and return the content loss between the content image and the\n",
    "    combination image (Scaled Euclidean distance).\n",
    "    '''\n",
    "\n",
    "    return K.sum(K.square(composition_np - content_np))\n",
    "\n",
    "\n",
    "def gram_matrix(image_np):\n",
    "    '''\n",
    "    Captures aggregate information about a particular image whilst ignoring \n",
    "    internal, structural detail.\n",
    "    '''\n",
    "\n",
    "    features = K.batch_flatten(K.permute_dimensions(image_np, (2, 0, 1)))\n",
    "    gram = K.dot(features, K.transpose(features))\n",
    "\n",
    "    return gram\n",
    "\n",
    "\n",
    "def style_loss(style_np, composition_np, height, width):\n",
    "    '''\n",
    "    Calculate style loss between style reference image and combination image.\n",
    "    Calculated as the scaled Frobenius norm of the difference between the Gram\n",
    "    matrices of the style/combination images.\n",
    "    '''\n",
    "\n",
    "    S = gram_matrix(style_np)\n",
    "    C = gram_matrix(composition_np)\n",
    "    channels = 3\n",
    "    size = height * width\n",
    "\n",
    "    return K.sum(K.square(S - C)) / (4. * (channels ** 2) * (size ** 2))\n",
    "\n",
    "\n",
    "def total_variation_loss(image_np, height, width):\n",
    "    '''\n",
    "    Reduce the noise present within the combined image by encnouraging spatial\n",
    "    smoothness, achieved via regularization.\n",
    "    '''\n",
    "\n",
    "    a = K.square(image_np[:, :height - 1, :width - 1,\n",
    "                          :] - image_np[:, 1:, :width - 1, :])\n",
    "    b = K.square(image_np[:, :height - 1, :width - 1, :] -\n",
    "                 image_np[:, :height - 1, 1:, :])\n",
    "\n",
    "    return K.sum(K.pow(a + b, 1.25))\n",
    "\n",
    "\n",
    "def total_loss(model, composition_np, content_weight, style_weight,\n",
    "               height, width, total_variation_weight):\n",
    "    '''\n",
    "    Return the total loss present within the combination image.\n",
    "    Total loss is calculated by considering the content, style and variation\n",
    "    loss.\n",
    "    '''\n",
    "\n",
    "    loss = K.variable(0.)\n",
    "\n",
    "    layers = dict([(layer.name, layer.output) for layer in model.layers])\n",
    "    layer_features = layers['block2_conv2']\n",
    "    content_features = layer_features[0, :, :, :]\n",
    "    composition_features = layer_features[2, :, :, :]\n",
    "\n",
    "    # content loss\n",
    "    loss += content_weight * \\\n",
    "        content_loss(content_features, composition_features)\n",
    "\n",
    "    # style loss calculation, retrieve all layers available for manipulation\n",
    "    feature_layers = ['block1_conv2', 'block2_conv2',\n",
    "                      'block3_conv3', 'block4_conv3',\n",
    "                      'block5_conv3']\n",
    "\n",
    "    for layer_name in feature_layers:\n",
    "        layer_features = layers[layer_name]\n",
    "        style_features = layer_features[1, :, :, :]\n",
    "        combination_features = layer_features[2, :, :, :]\n",
    "        sl = style_loss(style_features, combination_features, height, width)\n",
    "        loss += (style_weight / len(feature_layers)) * sl\n",
    "\n",
    "    # total variation loss\n",
    "    loss += total_variation_weight * \\\n",
    "        total_variation_loss(composition_np, height, width)\n",
    "    return loss  # return total loss\n",
    "\n",
    "\n",
    "def minimize_loss(save_name, loss, grads, composition_np, iterations, height, width):\n",
    "    '''\n",
    "    Using stochastic gradient descent via fmin_l_bfgs_b algorithm. Minimize\n",
    "    and balance the loss experienced over the course of 10 iterations.\n",
    "    Save the intermediate image combinations.\n",
    "    '''\n",
    "\n",
    "    x = np.random.uniform(0, 255, (1, height, width, 3)) - 128\n",
    "    evaluator = Evaluator(loss, grads, composition_np, height, width)\n",
    "\n",
    "    print(\"\\n\\nProcessing: \" + save_name)\n",
    "    for i in range(iterations):\n",
    "\n",
    "        # print diagnostic information\n",
    "        print('Start of iteration', i)\n",
    "        start_time = time.time()\n",
    "        x, min_val, info = scipy.optimize.fmin_l_bfgs_b(evaluator.loss,\n",
    "                                                        x.flatten(),\n",
    "                                                        fprime=evaluator.grads,\n",
    "                                                        maxfun=20)\n",
    "        print('Current loss value:', min_val)\n",
    "        end_time = time.time()\n",
    "        print('Iteration %d completed in %ds' % (i, end_time - start_time))\n",
    "    return x\n",
    "\n",
    "\n",
    "def create_composition_single(style_np, content_np, save_name, save_dir,\n",
    "                              height, width, content_weight, style_weight,\n",
    "                              total_variation_weight, iterations):\n",
    "    '''\n",
    "    Combine all components, create composite image with supplied\n",
    "    content and style image arrays.\n",
    "    '''\n",
    "\n",
    "    # placeholder composition image\n",
    "    composition_np = K.placeholder((1, height, width, 3))\n",
    "\n",
    "    # concat image arrays as single tensor\n",
    "    input_tensor = K.concatenate([content_np,\n",
    "                                  style_np,\n",
    "                                  composition_np], axis=0)\n",
    "\n",
    "    # load model\n",
    "    model = VGG16(input_tensor=input_tensor,\n",
    "                  weights='imagenet', include_top=False)\n",
    "\n",
    "    # define initial loss\n",
    "    loss = total_loss(model, composition_np, content_weight,\n",
    "                      style_weight, height, width,\n",
    "                      total_variation_weight)\n",
    "\n",
    "    # define initial gradients\n",
    "    grads = K.gradients(loss, composition_np)\n",
    "\n",
    "    # run optimization using previously calculated loss values\n",
    "    composition = minimize_loss(save_name, loss, grads,\n",
    "                                composition_np, iterations,\n",
    "                                height, width)\n",
    "\n",
    "    # 5.0 convert and finalize np array\n",
    "    export_image(composition, save_dir, height, width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import mkdir\n",
    "from util import retrieve_inputs, import_image\n",
    "from style_transfer import create_composition_single\n",
    "\n",
    "\n",
    "def main():\n",
    "\n",
    "    # parameterize composition model\n",
    "    content_weight = 0.025\n",
    "    style_weight = 5.0\n",
    "    variation_weight = 1.0\n",
    "    height = 50  # image downsample dimensions, min of 48x48 required\n",
    "    width = 50\n",
    "    iterations = 1\n",
    "\n",
    "    # retrieve all inputs\n",
    "    content_names, content_paths, style_names, style_paths = retrieve_inputs()\n",
    "\n",
    "    # for every content image\n",
    "    for cn, cp in zip(content_names, content_paths):\n",
    "        mkdir('./output/' + cn)\n",
    "        content_np = import_image(cp, height, width)\n",
    "\n",
    "        # create all possible content/style composition images\n",
    "        for sn, sp in zip(style_names, style_paths):\n",
    "            style_np = import_image(sp, height, width)\n",
    "            save_name = cn + '_' + sn\n",
    "            save_dir = './output/' + cn + '/' + save_name\n",
    "\n",
    "            create_composition_single(style_np, content_np,\n",
    "                                      save_name, save_dir,\n",
    "                                      height, width, content_weight,\n",
    "                                      style_weight, variation_weight,\n",
    "                                      iterations)\n",
    "\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
