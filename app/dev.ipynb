{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Processing: croat_boatsand_macro\n",
      "Start of iteration 0\n",
      "Current loss value: 8.56258e+09\n",
      "Iteration 0 completed in 30s\n"
     ]
    }
   ],
   "source": [
    "# '''\n",
    "# Image style transfer using convolutional neural networks.\n",
    "\n",
    "# A style image, content image and output image exist. The thrust of the script is\n",
    "# to minimize the content difference between the content image and the output image,\n",
    "# whilst simulatenously minimizing the style difference between the style image\n",
    "# and the output image. The output image exists as an intermediary between the\n",
    "# content and style images in which the structural elements of the content image\n",
    "# are blended with the stylistic components of the style image.\n",
    "# '''\n",
    "\n",
    "# # util\n",
    "# import numpy as np\n",
    "# import time\n",
    "# import scipy\n",
    "# from PIL import Image\n",
    "# from os import listdir, mkdir, getcwd\n",
    "\n",
    "# # keras backend\n",
    "# from keras.applications.vgg16 import VGG16  # \"OxfordNet\", pretrained network\n",
    "# from keras import backend as K\n",
    "# K.set_image_dim_ordering('tf')\n",
    "\n",
    "# def content_loss(content_np, composition_np):\n",
    "#     '''\n",
    "#     Calculate and return the content loss between the content image and the\n",
    "#     combination image. The scaled Euclidean distance between feature\n",
    "#     representations of the content and combination images.\n",
    "#     '''\n",
    "#     return K.sum(K.square(composition_np - content_np))\n",
    "\n",
    "\n",
    "# def gram_matrix(image_np):\n",
    "#     '''\n",
    "#     Captures information about which features within an image tend to \n",
    "#     activate with one another. Captures aggregate information about a particular\n",
    "#     image whilst ignoring internal, structural detail.\n",
    "#     '''\n",
    "#     features = K.batch_flatten(K.permute_dimensions(image_np, (2, 0, 1)))\n",
    "#     gram = K.dot(features, K.transpose(features))\n",
    "    \n",
    "#     return gram\n",
    "\n",
    "\n",
    "# def style_loss(style_np, composition_np):\n",
    "#     '''\n",
    "#     Calculate style loss between style reference image and combination image.\n",
    "#     Calculated as the scaled Frobenius norm of the difference between the Gram\n",
    "#     matrices of the style/combination images.\n",
    "#     '''\n",
    "#     S = gram_matrix(style_np)\n",
    "#     C = gram_matrix(composition_np)\n",
    "#     channels = 3\n",
    "#     size = height * width\n",
    "    \n",
    "#     return K.sum(K.square(S - C)) / (4. * (channels ** 2) * (size ** 2))\n",
    "\n",
    "\n",
    "# def total_variation_loss(image_np):\n",
    "#     '''\n",
    "#     Reduce the noise present within the combined image by encnouraging spatial\n",
    "#     smoothness via regularization.\n",
    "#     '''\n",
    "#     a = K.square(image_np[:, :height - 1, :width - 1, :] - image_np[:, 1:, :width - 1, :])\n",
    "#     b = K.square(image_np[:, :height - 1, :width - 1, :] - image_np[:, :height - 1, 1:, :])\n",
    "    \n",
    "#     return K.sum(K.pow(a + b, 1.25))\n",
    "\n",
    "\n",
    "# def total_loss(model, composition_np, content_weight):\n",
    "#     '''\n",
    "#     Return the total loss present within the combination image.\n",
    "#     Total loss is calculated by considering the content, style and variation\n",
    "#     loss.\n",
    "#     '''\n",
    "#     loss = K.variable(0.)\n",
    "\n",
    "#     layers = dict([(layer.name, layer.output) for layer in model.layers])\n",
    "#     layer_features = layers['block2_conv2']\n",
    "#     content_features = layer_features[0, :, :, :]\n",
    "#     composition_features = layer_features[2, :, :, :]\n",
    "\n",
    "#     # content loss\n",
    "#     loss += content_weight * content_loss(content_features,\n",
    "#                                           composition_features)\n",
    "\n",
    "#     # style loss calculation, retrieve all layers available for manipulation\n",
    "#     # within VGG model\n",
    "#     feature_layers = ['block1_conv2', 'block2_conv2',\n",
    "#                       'block3_conv3', 'block4_conv3',\n",
    "#                       'block5_conv3']\n",
    "\n",
    "#     for layer_name in feature_layers:\n",
    "#         layer_features = layers[layer_name]\n",
    "#         style_features = layer_features[1, :, :, :]\n",
    "#         combination_features = layer_features[2, :, :, :]\n",
    "#         sl = style_loss(style_features, combination_features)\n",
    "#         loss += (style_weight / len(feature_layers)) * sl\n",
    "\n",
    "#     # total variation loss\n",
    "#     loss += total_variation_weight * total_variation_loss(composition_np)\n",
    "#     return loss  # return total loss\n",
    "\n",
    "\n",
    "# def minimize_loss(save_name, loss, grads, composition_np, iterations):\n",
    "#     '''\n",
    "#     Using stochastic gradient descent via fmin_l_bfgs_b algorithm. Minimize\n",
    "#     and balance the loss experienced over the course of 10 iterations.\n",
    "#     Save the intermediate image combinations.\n",
    "#     '''\n",
    "#     x = np.random.uniform(0, 255, (1, height, width, 3)) - 128\n",
    "#     evaluator = Evaluator(loss, grads, composition_np)\n",
    "\n",
    "#     print(\"\\n\\nProcessing: \" + save_name)\n",
    "#     for i in range(iterations):\n",
    "\n",
    "#         # print diagnostic information\n",
    "#         print('Start of iteration', i)\n",
    "#         start_time = time.time()\n",
    "#         x, min_val, info = scipy.optimize.fmin_l_bfgs_b(evaluator.loss,\n",
    "#                                                         x.flatten(),\n",
    "#                                                         fprime=evaluator.grads,\n",
    "#                                                         maxfun=20)\n",
    "#         print('Current loss value:', min_val)\n",
    "#         end_time = time.time()\n",
    "#         print('Iteration %d completed in %ds' % (i, end_time - start_time))\n",
    "#     return x\n",
    "\n",
    "\n",
    "# def eval_loss_and_grads(x, loss, grads, composition_np):\n",
    "#     '''\n",
    "#     Define gradients of the total loss relative to the combination image, in\n",
    "#     order to minimize the loss.\n",
    "#     '''\n",
    "#     x = x.reshape((1, height, width, 3))\n",
    "#     outputs = [loss]\n",
    "#     outputs += grads\n",
    "#     f_outputs = K.function([composition_np], outputs)\n",
    "\n",
    "#     outs = f_outputs([x])\n",
    "#     loss_value = outs[0]\n",
    "#     grad_values = outs[1].flatten().astype('float64')\n",
    "#     return loss_value, grad_values\n",
    "\n",
    "# class Evaluator(object):\n",
    "#     '''\n",
    "#     Computes the loss and gradient present within the combination image. Phrased\n",
    "#     as a class to conveniently package retrieval methods for interfacing with \n",
    "#     scypy.optimize library.\n",
    "#     '''\n",
    "\n",
    "#     def __init__(self, il, ig, comb_np):\n",
    "#         self.loss_value = None\n",
    "#         self.grads_values = None\n",
    "#         self.initial_loss = il\n",
    "#         self.initial_grad = ig\n",
    "#         self.comb_np = comb_np\n",
    "\n",
    "#     def loss(self, x):\n",
    "#         '''\n",
    "#         Retrieve the loss value for the combination image.\n",
    "#         '''\n",
    "#         assert self.loss_value is None\n",
    "#         loss_value, grad_values = eval_loss_and_grads(\n",
    "#             x, self.initial_loss, self.initial_grad, self.comb_np)\n",
    "#         self.loss_value = loss_value\n",
    "#         self.grad_values = grad_values\n",
    "#         return self.loss_value\n",
    "\n",
    "#     def grads(self, x):\n",
    "#         '''\n",
    "#         Retrieve the gradients associated with a particular combination\n",
    "#         image.\n",
    "#         '''\n",
    "#         assert self.loss_value is not None\n",
    "#         grad_values = np.copy(self.grad_values)\n",
    "#         self.loss_value = None\n",
    "#         self.grad_values = None\n",
    "#         return grad_values\n",
    "\n",
    "# def import_image(file_name):\n",
    "#     image = Image.open(file_name)# 1.0 retrieve all input image references\n",
    "#     # resize (downsample)\n",
    "#     image = image.resize((height, width), Image.ANTIALIAS)\n",
    "#     image = np.asarray(image, dtype='float32')  # cast to np array\n",
    "#     image = np.expand_dims(image, axis=0)  # add placeholder dimension\n",
    "\n",
    "#     image[:, :, :, 0] -= 103.939  # subtract mean RGB values from ImageNet\n",
    "#     image[:, :, :, 1] -= 116.779\n",
    "#     image[:, :, :, 2] -= 123.68\n",
    "#     # flip RGB pixel ordering => match Simonyan/Sizzerman paper\n",
    "#     image = image[:, :, :, ::-1]\n",
    "#     return image\n",
    "\n",
    "\n",
    "# def export_image(img_array, save_dir):\n",
    "#     img_array = img_array.reshape((height, width, 3))  # reshape\n",
    "#     img_array = img_array[:, :, ::-1]  # flip RGB pixel ordering\n",
    "#     img_array[:, :, 0] += 103.939  # add mean RGB values from ImageNet\n",
    "#     img_array[:, :, 1] += 116.779\n",
    "#     img_array[:, :, 2] += 123.68\n",
    "#     img_array = np.clip(img_array, 0, 255).astype(\n",
    "#         'uint8')  # trim wayward pixels\n",
    "#     Image.fromarray(img_array).save(save_dir + '.jpeg', \"jpeg\")  # save\n",
    "\n",
    "\n",
    "# def retrieve_inputs():\n",
    "#     content_names = list(os.path.splitext(\n",
    "#         each)[0] for each in listdir(\"../input/contents\"))\n",
    "#     content_paths = glob.glob('../input/contents/*')\n",
    "#     style_names = list(os.path.splitext(each)[0]\n",
    "#                        for each in listdir(\"../input/styles\"))\n",
    "#     style_paths = glob.glob('../input/styles/*')\n",
    "#     return content_names, content_paths, style_names, style_paths\n",
    "\n",
    "\n",
    "# def create_composition_single(style_np, content_np, save_name, save_dir):\n",
    "\n",
    "#     # 3.2 create placeholder image, used to store merger image\n",
    "#     composition_np = K.placeholder((1, height, width, 3))\n",
    "\n",
    "#     # 3.3 concatenate the image arrays\n",
    "#     input_tensor = K.concatenate([content_np,\n",
    "#                                   style_np,\n",
    "#                                   composition_np], axis=0)\n",
    "\n",
    "#     # 4.0 load model, iteratively merge and consolidate the two images\n",
    "#     # 4.1 load the model\n",
    "#     model = VGG16(input_tensor=input_tensor,\n",
    "#                   weights='imagenet', include_top=False)\n",
    "\n",
    "#     # 4.2 calculate combination loss\n",
    "#     loss = total_loss(model, composition_np, content_weight)\n",
    "\n",
    "#     # 4.3 calulate gradients of generated image\n",
    "#     grads = K.gradients(loss, composition_np)\n",
    "\n",
    "#     # 4.4 run optimization using previously calculated loss values\n",
    "#     composition = minimize_loss(save_name, loss, grads, composition_np,1)\n",
    "\n",
    "#     # 5.0 convert and finalize np array\n",
    "#     export_image(composition, save_dir)\n",
    "\n",
    "def main():\n",
    "    \n",
    "    #parameterize composition model\n",
    "    content_weight = 0.025\n",
    "    style_weight = 5.0\n",
    "    total_variation_weight = 1.0\n",
    "    height = 49 #minimum dimensions of 48, VGG16 requirements\n",
    "    width = 49\n",
    "\n",
    "    #input images\n",
    "    content_names, content_paths, style_names, style_paths = retrieve_inputs()\n",
    "\n",
    "    #for every content image\n",
    "    for cn, cp in zip(content_names, content_paths):\n",
    "        mkdir('../output/' + cn) #\n",
    "        content_np = import_image(cp)\n",
    "\n",
    "        # create all possible content/style composition images\n",
    "        for sn, sp in zip(style_names, style_paths):\n",
    "            style_np = import_image(sp)\n",
    "            save_name = cn + sn\n",
    "            save_dir = '../output/' + cn + '/' + sn\n",
    "            create_composition_single(style_np, content_np, save_name, save_dir)\n",
    "            \n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
